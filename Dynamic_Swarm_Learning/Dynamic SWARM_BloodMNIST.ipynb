{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"siQdg4qXy_7i"},"outputs":[],"source":["!pip install medmnist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWhVdMYWiPhe"},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from torchvision import datasets, transforms\n","import sklearn\n","from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import os\n","from collections import Counter\n","from google.colab import drive\n","import concurrent.futures\n","import time\n","import random\n","from medmnist import BloodMNIST\n","import csv\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kqCkRdibcHu"},"outputs":[],"source":["# Mount Google Drive for persistent storage\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTUlgE767jNL"},"outputs":[],"source":["NUM_NODES = 4\n","NUM_GLOBAL_EPOCHS = 5\n","NUM_LOCAL_EPOCHS = 5\n","train_size = 0.9\n","test_size = 0.1\n","BATCH_SIZE = 64\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TNUYGvn7kud"},"outputs":[],"source":["def load_data():\n","\n","  # Define the transformations\n","  transform = transforms.Compose([\n","      transforms.Resize((256, 256)),  # Resize to match the input size of the model\n","      transforms.ToTensor(),  # Convert images to tensor\n","      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n","  ])\n","\n","  test_dataset = BloodMNIST(split=\"test\", download=True, transform=transform)\n","  train_dataset = BloodMNIST(split=\"train\", download=True, transform=transform)\n","\n","\n","  print(\"Data has been loaded\")\n","  return train_dataset, test_dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3QDUXPs7nSE"},"outputs":[],"source":["def split_data_nodes(dataset, num_nodes):\n","  # Determine the sizes of each split\n","  dataset_size = len(dataset)\n","  indices = list(range(dataset_size))\n","  np.random.shuffle(indices)\n","\n","  split_sizes = np.random.randint(1, dataset_size // num_nodes + 1, size=num_nodes - 1)\n","  split_sizes = np.append(split_sizes, dataset_size - split_sizes.sum())\n","  np.random.shuffle(split_sizes)\n","\n","  # Create random splits\n","  subsets = []\n","  start = 0\n","  for size in split_sizes:\n","      subset_indices = indices[start:start + size]\n","      subsets.append(subset_indices)\n","      start += size\n","\n","\n","  # Apply the splits to the dataset\n","  dataset_splits = [torch.utils.data.Subset(dataset, subset) for subset in subsets]\n","\n","  # Calculate the size weightings for each subset\n","  weightings = [len(subset) / dataset_size for subset in dataset_splits]\n","\n","\n","\n","  print(\"Data has been split into \" + str(num_nodes) + \" nodes\")\n","  # Print the size of each data subset\n","  for i, subset in enumerate(dataset_splits):\n","      print(f'Size of subset {i+1}: {len(subset)}')\n","\n","\n","  return dataset_splits, dataset, weightings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BkMLI52P7pK7"},"outputs":[],"source":["def create_data_loaders(subset):\n","\n","    # Split into train and validation (adjust validation split as needed)\n","    val_size = int(0.2 * len(subset))\n","    train_size = len(subset) - val_size\n","    train_subset, val_subset = torch.utils.data.random_split(subset, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    print(\"Data Loader Created\")\n","    return train_loader, val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l3iwOOHh8N9k"},"outputs":[],"source":["class SimpleNN(nn.Module):\n","    def __init__(self, input_size=256*256*3, num_classes=8):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 128)\n","        self.fc2 = nn.Linear(128, num_classes)  # Ensure num_classes matches dataset\n","\n","    def forward(self, x):\n","        x = x.view(-1, 256*256*3)  # Flatten the image\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjzhD9GP8T7H"},"outputs":[],"source":["def create_final_data_test_loader(final_testing):\n","  final_model_test_loader = torch.utils.data.DataLoader(final_testing, batch_size=BATCH_SIZE, shuffle=False)\n","  return final_model_test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYvQtkbxcDBU"},"outputs":[],"source":["def model_parameters_to_string(model):\n","    params_str = \"Model Parameters:\\n\"\n","    for name, param in model.named_parameters():\n","        params_str += f\"Name: {name}, Shape: {param.shape}\\n\"\n","        params_str += f\"{param.data}\\n\"\n","        params_str += \"-\" * 50 + \"\\n\"\n","    return params_str"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"6waIo5ZS7rh-"},"outputs":[],"source":["\n","class Node:\n","    def __init__(self, node_id, train_loader: DataLoader, test_loader: DataLoader, weighting, aggregation_methodology):\n","        \"\"\"\n","        Initialize the Node with training and testing DataLoaders.\n","\n","        Parameters:\n","        train_loader (DataLoader): DataLoader for training data.\n","        test_loader (DataLoader): DataLoader for testing data.\n","        \"\"\"\n","        self.__train_loader = train_loader\n","        self.test_loader = test_loader\n","        self.node_id = node_id\n","        self.global_parameters = []\n","        self.accuracy = None\n","        self.model = SimpleNN(num_classes=8)\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n","        self.accuracy_scores = []\n","        self.current_accuracy = 0\n","        self.accuracy_scores = []\n","        self.f1_scores = []\n","        self.precision_scores = []\n","        self.recall_scores = []\n","        self.weighting = weighting\n","        self.aggregation_methodology = aggregation_methodology\n","        self.balance_score = self.get_balance_score()\n","\n","    def get_model(self):\n","      return self.model\n","\n","    def get_balance_score(self):\n","        class_counts = np.zeros(10, dtype=int)  # MNIST has 10 classes (0-9)\n","        for _, label in self.__train_loader:\n","            class_counts[label] += 1\n","        total_samples = sum(class_counts)\n","        if total_samples == 0:\n","            return 0\n","        class_proportions = np.array(class_counts) / total_samples\n","        score = 1 - np.std(class_proportions)\n","        return score\n","\n","    def get_final_scores(self):\n","\n","      \"\"\"\n","      Convert performance metrics lists into a pandas DataFrame.\n","\n","      Parameters:\n","      accuracy_scores (list): List of accuracy scores.\n","      precision_scores (list): List of precision scores.\n","      recall_scores (list): List of recall scores.\n","      f1_scores (list): List of F1 scores.\n","\n","      Returns:\n","      pd.DataFrame: DataFrame containing the metrics.\n","      \"\"\"\n","      # Create a dictionary from the lists\n","      metrics_dict = {\n","          'Accuracy': self.accuracy_scores,\n","          'Precision': self.precision_scores,\n","          'Recall': self.recall_scores,\n","          'F1 Score': self.f1_scores\n","      }\n","\n","      # Convert the dictionary into a DataFrame\n","      df = pd.DataFrame(metrics_dict)\n","\n","      return df\n","\n","    def get_accuracy_score(self):\n","      return self.current_accuracy\n","\n","    def set_accuracy_score(self, accuracy):\n","      self.current_accuracy = accuracy\n","\n","    def get_node_id(self):\n","      return self.node_id\n","\n","    def set_aggregation_methodology(self, methodology):\n","      self.aggregation_methodology = methodology\n","\n","    def get_test_loader(self) -> DataLoader:\n","        \"\"\"\n","        Return the testing DataLoader.\n","\n","        Returns:\n","        DataLoader: The testing DataLoader.\n","        \"\"\"\n","        return self.test_loader\n","\n","    def broadcast_parameters(self):\n","        \"\"\"\n","        Return the model parameters.\n","\n","        Returns:\n","        dict: Dictionary of model parameters.\n","        \"\"\"\n","        return_list = []\n","        for param in self.model.parameters():\n","          return_list.append(param.clone())\n","\n","        return_list.insert(0, self.current_accuracy)\n","        return_list.insert(0, self.weighting)\n","        return_list.insert(0, self.balance_score)\n","\n","        return return_list\n","\n","\n","    def gather_parameters(self, params):\n","        print(\"Gathered Parameters for Node \" + str(self.node_id))\n","        self.global_parameters.append(params)\n","        print(\"Length of Gathered Parameters for Node \" + str(self.node_id) + \" : \" + str(len(self.global_parameters)))\n","\n","    def size_average_parameters(self):\n","            averaged_params = []\n","            print(\"Size of global params: \" + str(len(self.global_parameters)))\n","\n","            # Create a copy of global_parameters without modifying the original\n","            params = [param[:] for param in self.global_parameters]  # Shallow copy of each param list\n","            weightings = []\n","\n","            # Extract non-tensor elements without modifying the original\n","            for param_set in params:\n","                balance_score = param_set[0]  # Access without popping (no removal)\n","                weighting = param_set[1]      # Access weighting\n","                accuracy = param_set[2]       # Access accuracy\n","\n","                weightings.append(weighting)\n","\n","            # Clone the tensors and initialize averaged_params\n","            for param in params[0][3:]:  # Skip non-tensor elements (balance, weighting, accuracy)\n","                averaged_params.append(torch.zeros_like(param))  # Initialize with zeros\n","\n","            # Sum the parameters with their corresponding weights\n","            total_weight = 0\n","            for model_params, weight in zip(params, weightings):\n","                model_params = model_params[3:]  # Exclude non-tensor elements\n","                if len(model_params) != len(averaged_params):\n","                    raise ValueError(\"Mismatch in the number of parameters between models.\")\n","\n","                for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","                    if param.shape != avg_param.shape:\n","                        raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","                    averaged_params[i] += param * weight\n","                total_weight += weight\n","\n","            # Normalize by the total weight\n","            if total_weight > 0:\n","                for i in range(len(averaged_params)):\n","                    averaged_params[i] /= total_weight\n","\n","            return averaged_params\n","\n","\n","\n","\n","\n","    def balance_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","\n","      # Create a shallow copy of the global parameters to avoid mutation\n","      params = [param[:] for param in self.global_parameters]  # Shallow copy of each param list\n","      balance_scores = []\n","\n","      # Extract non-tensor elements (balance scores, weightings, accuracy) without modifying the original\n","      for param_set in params:\n","          balance_score = param_set[0]  # Access balance score\n","          weighting = param_set[1]      # Access weighting (but not needed)\n","          accuracy = param_set[2]       # Access accuracy (but not needed)\n","          print(\"Balance Score: \" + str(balance_score))\n","          balance_scores.append(balance_score)\n","\n","      # Clone the tensors and initialize averaged_params with zeros\n","      for param in params[0][3:]:  # Skip first three elements (balance, weighting, accuracy)\n","          averaged_params.append(torch.zeros_like(param))  # Initialize with zeros\n","\n","      # Sum the parameters with their corresponding balance scores\n","      total_balance_scores = 0\n","      for model_params, balance_score in zip(params, balance_scores):\n","          model_params = model_params[3:]  # Exclude the first three non-tensor elements\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * balance_score\n","          total_balance_scores += balance_score\n","\n","      # Normalize by the total balance scores\n","      if total_balance_scores > 0:\n","          print(\"Total Balance Scores: \" + str(total_balance_scores))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_balance_scores\n","\n","      return averaged_params\n","\n","    def test_aggregation(self):\n","      size_model = copy.deepcopy(self.model)  # Make a copy of the model\n","      balance_model = copy.deepcopy(self.model)  # Make another copy of the model\n","      averaged_size_params = self.size_average_parameters()\n","      size_state_dict = dict(zip(size_model.state_dict().keys(), averaged_size_params))\n","      size_model.load_state_dict(size_state_dict)\n","\n","      averaged_balance_params = self.balance_average_parameters()\n","      balance_state_dict = dict(zip(balance_model.state_dict().keys(), averaged_balance_params))\n","      balance_model.load_state_dict(balance_state_dict)\n","\n","      size_accuracy, size_precision, size_recall, size_f1 = evaluate(size_model, self.test_loader)\n","      balance_accuracy, balance_precision, balance_recall, balance_f1 = evaluate(balance_model, self.test_loader)\n","      print(\"Size Accuracy: \" + str(size_accuracy))\n","      print(\"Balance Accuracy: \" + str(balance_accuracy))\n","      if size_accuracy > balance_accuracy:\n","        return \"size\"\n","      else:\n","        return \"balance\"\n","\n","\n","\n","    def aggregate_parameters(self):\n","      if self.aggregation_methodology == \"size_average\":\n","        averaged_params = self.size_average_parameters()\n","      elif self.aggregation_methodology == \"balance_average\":\n","        averaged_params = self.balance_average_parameters()\n","      else:\n","        raise ValueError(\"Invalid aggregation methodology. Use 'average' or 'size_average' or 'accuracy_average'.\")\n","\n","      print(\"Length of Averaged Params for node \" + str(self.node_id) + \" : \" + str(len(averaged_params)))\n","      self.set_parameters(averaged_params)\n","\n","      self.global_parameters = []\n","\n","\n","    def set_parameters(self, parameters):\n","\n","        \"\"\"\n","        Set the model parameters.\n","\n","        Parameters:\n","        parameters (dict): Dictionary of model parameters.\n","        \"\"\"\n","        # Convert the list of averaged parameters back into the correct format for the model\n","        print(\"Setting Parameters for node: \" + str(self.node_id))\n","        new_state_dict = dict(zip(self.model.state_dict().keys(), parameters))\n","        self.model.load_state_dict(new_state_dict)\n","        print(\"Set Parameters for node \" + str(self.node_id) + \" : \" + str(model_parameters_to_string(self.model)))\n","\n","\n","\n","    def train(self):\n","\n","      # Move model to the specified device\n","      self.model.to(device)\n","\n","      for epoch in range(NUM_LOCAL_EPOCHS):\n","\n","        self.model.train()\n","        running_loss = 0.0\n","\n","        for images, labels in self.__train_loader:\n","            # Move images and labels to the specified device\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Flatten the labels tensor to be 1D\n","            if len(labels.shape) == 2:\n","                labels = labels.squeeze(1)  # Remove the extra dimension\n","\n","            # Check for label values out of bounds\n","            if labels.max() >= 8:\n","                raise ValueError(f\"Label value {labels.max()} is out of bounds for the number of classes {8}.\")\n","\n","            # Ensure labels are 1D\n","            if len(labels.shape) != 1:\n","                raise ValueError(\"Labels tensor is not 1D. It should be of shape [batch_size].\")\n","\n","            self.optimizer.zero_grad()\n","            outputs = self.model(images)\n","\n","            # Ensure labels are of type long\n","            labels = labels.long()\n","\n","            loss = self.criterion(outputs, labels)\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            running_loss += loss.item()\n","      # Print the average loss for this epoch\n","        print(f\"Epoch [{epoch+1}/{NUM_LOCAL_EPOCHS}], Training Loss: {running_loss / len(train_loader)}\")\n","\n","\n","    def evaluate(self):\n","        self.model.eval()  # Set the model to evaluation mode\n","\n","        all_labels = []\n","        all_predictions = []\n","\n","        with torch.no_grad():  # No need to calculate gradients during evaluation\n","            for images, labels in self.test_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = self.model(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                all_labels.extend(labels.cpu().numpy())\n","                all_predictions.extend(predicted.cpu().numpy())\n","\n","        # Convert lists to numpy arrays for sklearn metrics\n","        all_labels = np.array(all_labels).flatten()\n","        all_predictions = np.array(all_predictions)\n","\n","        # Calculate metrics\n","        accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","        precision = precision_score(all_labels, all_predictions, average='weighted')\n","        recall = recall_score(all_labels, all_predictions, average='weighted')\n","        f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","        self.accuracy_scores.append(accuracy)\n","        self.precision_scores.append(precision)\n","        self.recall_scores.append(recall)\n","        self.f1_scores.append(f1)\n","        self.set_accuracy_score(accuracy)\n","        return accuracy, precision, recall, f1\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qK8K79a2NKnM"},"outputs":[],"source":["def train_and_communicate(node, nodes):\n","    node.train()\n","    metrics = node.evaluate()\n","    print(\"Metrics for Node \" + str(node.get_node_id()) + \" : \" + str(metrics))\n","    # Send parameters to all other nodes\n","    for other_node in nodes:\n","      print(\"NODE \" + str(node.get_node_id()) + \"  HAS BROADCASTED \")\n","\n","      other_node.gather_parameters(node.broadcast_parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZB_PKFLfebE"},"outputs":[],"source":["def dynamic_aggregation(nodes):\n","  decisions = []\n","  for node in nodes:\n","    decisions.append(node.test_aggregation())\n","  if decisions.count(\"size\") > decisions.count(\"balance\"):\n","    for node in nodes:\n","      node.set_aggregation_methodology(\"size_average\")\n","    return \"balance\"\n","  elif decisions.count(\"size\") < decisions.count(\"balance\"):\n","    for node in nodes:\n","      node.set_aggregation_methodology(\"balance_average\")\n","    return \"size\"\n","  else:\n","    for node in nodes:\n","      node.set_aggregation_methodology(\"balance_average\")\n","\n","    return \"size\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUE36X0v1pyp"},"outputs":[],"source":["def evaluate(model, test_loader):\n","  model.eval()  # Set the model to evaluation mode\n","\n","  all_labels = []\n","  all_predictions = []\n","\n","  with torch.no_grad():  # No need to calculate gradients during evaluation\n","      for images, labels in test_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          all_labels.extend(labels.cpu().numpy())\n","          all_predictions.extend(predicted.cpu().numpy())\n","\n","  # Convert lists to numpy arrays for sklearn metrics\n","  all_labels = np.array(all_labels).flatten()\n","  all_predictions = np.array(all_predictions)\n","\n","    # Print the shapes of the arrays\n","  print(f\"Shape of all_labels: {all_labels.shape}\")\n","  print(f\"Shape of all_predictions: {all_predictions.shape}\")\n","\n","\n","  print(f\"Unique labels: {np.unique(all_labels)}\")\n","  print(f\"Unique predictions: {np.unique(all_predictions)}\")\n","\n","\n","  print(f\"Sample Labels: {all_labels[:10]}\")\n","  print(f\"Sample Predictions: {all_predictions[:10]}\")\n","\n","  print(\"Num Correct: \" + str(np.sum(all_predictions == all_labels)))\n","\n","  # Calculate metrics\n","  accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","  precision = precision_score(all_labels, all_predictions, average='weighted')\n","  recall = recall_score(all_labels, all_predictions, average='weighted')\n","  f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","  return accuracy, precision, recall, f1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtHShANb18kl"},"outputs":[],"source":["# Function to write the metrics to a CSV file\n","def write_metrics_to_csv(filename, metrics_list):\n","    file_exists = os.path.isfile(filename)\n","\n","    with open(filename, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","\n","        # Write the header only if the file is being created\n","        if not file_exists:\n","            writer.writerow(['Aggregation Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n","\n","        # Write the data\n","        writer.writerow(metrics_list)\n","\n","    print(f'Metrics written to {filename}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HVY_x9mNP_r"},"outputs":[],"source":["for i in range(10):\n","    print(\"Swarm Number: \" + str(i))\n","    dataset, testing_set = load_data()\n","\n","    #split data into final testing and data for nodes\n","    subsets, dataset, weightings = split_data_nodes(dataset, NUM_NODES)\n","\n","    #create the final test loader and set it\n","    final_test_loader = create_final_data_test_loader(testing_set)\n","\n","    nodes = []\n","    for i in range(0,NUM_NODES):\n","      train_loader, val_loader =  create_data_loaders(subsets[i])\n","      node = Node(i, train_loader, val_loader, weightings[i], \"balance_average\")\n","      nodes.append(node)\n","\n","    winners = []\n","    # Training and aggregation process\n","    for _ in range(NUM_GLOBAL_EPOCHS):  # Number of training rounds\n","        print(\"Round \" + str(_))\n","        with concurrent.futures.ThreadPoolExecutor() as executor:\n","            executor.map(train_and_communicate, nodes, [nodes]*len(nodes))\n","\n","        if _ < NUM_GLOBAL_EPOCHS / 2:\n","            winner = dynamic_aggregation(nodes)\n","            winners.append(winner)\n","            print(\"Winners: \" + str(winners))\n","        else:\n","            winner = max(set(winners), key=winners.count)\n","            print(\"Winner: \" + str(winner))\n","            if winner == \"size\":\n","                for node in nodes:\n","                    node.set_aggregation_methodology(\"size_average\")\n","            elif winner == \"balance\":\n","                for node in nodes:\n","                    node.set_aggregation_methodology(\"balance_average\")\n","            else:\n","              print(\"MAJOR ERROR: Winner is in fact: \" + str(winner))\n","\n","        # Aggregation phase\n","        for node in nodes:\n","\n","          updated_params = node.aggregate_parameters()\n","\n","        time.sleep(1)  # Simulate time between rounds\n","\n","\n","    node = nodes[0]\n","\n","    accuracy, precision, recall, f1 = evaluate(node.get_model(), final_test_loader)\n","    filename = '/content/drive/My Drive/Swarm_Learning/dynamic_bloodMNIST.csv'\n","    metrics_list = [accuracy, precision, recall, f1]\n","    write_metrics_to_csv(filename, metrics_list)\n","\n","\n","\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyONNhrJ6qqQ0B/yQhEAzxQ+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}