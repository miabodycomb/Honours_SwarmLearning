{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4f2QMSAX4h9p"},"outputs":[],"source":["!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWhVdMYWiPhe"},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from torchvision import datasets, transforms\n","from torchvision.models import mobilenet_v2\n","import sklearn\n","from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset, Dataset\n","from torchvision.datasets.folder import default_loader\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import os\n","from google.colab import drive\n","import concurrent.futures\n","import time\n","import random\n","import csv\n","import torch.nn.functional as F  # Import functional module\n","from tqdm import tqdm\n","from torch.optim import AdamW\n","import timm\n","import copy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kqCkRdibcHu"},"outputs":[],"source":["# Mount Google Drive for persistent storage\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTUlgE767jNL"},"outputs":[],"source":["NUM_NODES = 4\n","NUM_GLOBAL_EPOCHS = 5\n","NUM_LOCAL_EPOCHS = 5\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TNUYGvn7kud"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, root_dirs, class_labels, transform=None):\n","        self.transform = transform\n","        self.samples = []\n","        self.labels = set()  # Used to store unique tag sets\n","\n","        # Loop through each category's directory and read the files\n","        for i, dirs in enumerate(root_dirs):\n","            for dir_path in dirs:\n","                for img_name in os.listdir(dir_path):\n","                    img_path = os.path.join(dir_path, img_name)\n","                    self.samples.append((img_path, i))  # Use index as label\n","                    self.labels.add(class_labels[i])\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, index):\n","        path, label = self.samples[index]\n","        sample = default_loader(path)\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","        return sample, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yrCHf9ofShkM"},"outputs":[],"source":["def load_data():\n","    transform = transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(20),\n","        transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","    ])\n","\n","    # Use the CustomDataset\n","    root_dirs = [\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/Benign'],\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/[Malignant] Pre-B'],\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/[Malignant] Pro-B'],\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/[Malignant] early Pre-B']\n","    ]\n","    class_labels = ['Benign', 'Malignant_Pre-B', 'Malignant_Pro-B', 'Malignant_early Pre-B']\n","    dataset = CustomDataset(root_dirs, class_labels, transform=transform)\n","    num_classes = len(dataset.labels)\n","    print(\"Number of samples in the dataset:\", len(dataset))\n","    print(\"Detected number of classes:\", num_classes)\n","\n","    # Split the dataset into training and testing sets (80% train, 20% test)\n","    train_size = int(0.8 * len(dataset))\n","    test_size = len(dataset) - train_size\n","    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","    return train_dataset, test_dataset, num_classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3QDUXPs7nSE"},"outputs":[],"source":["def split_data_nodes(dataset, num_nodes):\n","  # Determine the sizes of each split\n","  dataset_size = len(dataset)\n","  indices = list(range(dataset_size))\n","  np.random.shuffle(indices)\n","\n","  split_sizes = np.random.randint(1, dataset_size // num_nodes + 1, size=num_nodes - 1)\n","  split_sizes = np.append(split_sizes, dataset_size - split_sizes.sum())\n","  np.random.shuffle(split_sizes)\n","\n","  # Create random splits\n","  subsets = []\n","  start = 0\n","  for size in split_sizes:\n","      subset_indices = indices[start:start + size]\n","      subsets.append(subset_indices)\n","      start += size\n","\n","\n","  # Apply the splits to the dataset\n","  dataset_splits = [torch.utils.data.Subset(dataset, subset) for subset in subsets]\n","\n","  # Calculate the size weightings for each subset\n","  weightings = [len(subset) / dataset_size for subset in dataset_splits]\n","\n","\n","\n","  print(\"Data has been split into \" + str(num_nodes) + \" nodes\")\n","  # Print the size of each data subset\n","  for i, subset in enumerate(dataset_splits):\n","      print(f'Size of subset {i+1}: {len(subset)}')\n","\n","\n","  return dataset_splits, dataset, weightings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BkMLI52P7pK7"},"outputs":[],"source":["def create_data_loaders(subset):\n","    # batch_size = 64\n","\n","    # Split into train and validation (adjust validation split as needed)\n","    val_size = int(0.2 * len(subset))\n","    train_size = len(subset) - val_size\n","    train_subset, val_subset = torch.utils.data.random_split(subset, [train_size, val_size])\n","\n","    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    print(\"Data Loader Created\")\n","    return train_loader, val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssUtfq0gXqN4"},"outputs":[],"source":["class SwinTransformerModel(nn.Module):\n","    def __init__(self, num_classes=4):\n","        super(SwinTransformerModel, self).__init__()\n","        self.swin_transformer = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)\n","\n","        # Freeze all parameters of the pre-trained model\n","        for param in self.swin_transformer.parameters():\n","            param.requires_grad = False\n","\n","        # Get the number of input features for the last layer\n","        num_features = self.swin_transformer.head.in_features\n","        self.swin_transformer.head = nn.Sequential(\n","            nn.Dropout(0.5),  # Adding Dropout Layers to Reduce Overfitting\n","            nn.Linear(num_features, 512),  # Top level fully connected layer\n","            nn.ReLU(),  # Activation function\n","            nn.Linear(512, num_classes)  # Output layer\n","        )\n","\n","        # Ensure that only the parameters of the newly added fully connected layer are updated\n","        for param in self.swin_transformer.head.parameters():\n","            param.requires_grad = True\n","\n","        for name, param in self.swin_transformer.named_parameters():\n","            if name in ['layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias']:\n","                param.requires_grad = True\n","\n","        # Add a global average pooling layer to handle the spatial dimensions\n","        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","    def forward(self, x):\n","        x = self.swin_transformer.forward_features(x)  # Extract features\n","\n","        # Adjust the dimension order\n","        x = x.permute(0, 3, 1, 2)  # From [32, 7, 7, 768] to [32, 768, 7, 7]\n","\n","        # Apply global average pooling\n","        x = self.global_avg_pool(x)  # From [32, 768, 7, 7] to [32, 768, 1, 1]\n","\n","        x = torch.flatten(x, 1)  # Flatten from [32, 768, 1, 1] to [32, 768]\n","        x = self.swin_transformer.head(x)  # Apply fully connected layer\n","\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6-q7M_KpTTuX"},"outputs":[],"source":["class MobileNetV2(nn.Module):\n","    def __init__(self, num_classes=4, unfreeze_blocks=None):\n","        super(MobileNetV2, self).__init__()\n","        self.mobilenet = mobilenet_v2(pretrained=True)\n","\n","        if unfreeze_blocks is not None:\n","            for name, parameter in self.mobilenet.named_parameters():\n","                if any(block in name for block in unfreeze_blocks):\n","                    parameter.requires_grad = True\n","\n","        num_features = self.mobilenet.classifier[1].in_features\n","        self.mobilenet.classifier[1] = nn.Linear(num_features, num_classes)\n","\n","        for param in self.mobilenet.classifier.parameters():\n","            param.requires_grad = True\n","\n","    def forward(self, x):\n","        return self.mobilenet(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0QWqTylRHuhy"},"outputs":[],"source":["class SimpleNN(nn.Module):\n","    def __init__(self, input_size=224*224*3, num_classes=4):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 128)\n","        self.fc2 = nn.Linear(128, num_classes)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 224*224*3)  # Adjust the flattening step\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjzhD9GP8T7H"},"outputs":[],"source":["def create_final_data_test_loader(final_testing):\n","  final_model_test_loader = torch.utils.data.DataLoader(final_testing, batch_size=BATCH_SIZE, shuffle=False)\n","  return final_model_test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6waIo5ZS7rh-"},"outputs":[],"source":["class Node:\n","    def __init__(self, node_id, train_loader: DataLoader, test_loader: DataLoader, weighting, aggregation_methodology):\n","        \"\"\"\n","        Initialize the Node with training and testing DataLoaders.\n","\n","        Parameters:\n","        train_loader (DataLoader): DataLoader for training data.\n","        test_loader (DataLoader): DataLoader for testing data.\n","        \"\"\"\n","        self.__train_loader = train_loader\n","        self.test_loader = test_loader\n","        self.node_id = node_id\n","        self.global_parameters = []\n","        self.accuracy = None\n","        self.model = SwinTransformerModel() ##num_classes = 4\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=0.01)\n","        self.accuracy_scores = []\n","        self.current_accuracy = 0\n","        self.accuracy_scores = []\n","        self.f1_scores = []\n","        self.precision_scores = []\n","        self.recall_scores = []\n","        self.weighting = weighting\n","        self.aggregation_methodology = aggregation_methodology\n","        self.balance_score = self.get_balance_score()\n","\n","    def get_model(self):\n","      return self.model\n","\n","\n","    def get_balance_score(self):\n","      class_counts = torch.zeros(4, dtype=int)  # 4 classes\n","      for _, label in self.__train_loader:\n","          class_counts += torch.bincount(label, minlength=4)\n","\n","      total_samples = class_counts.sum().item()\n","      if total_samples == 0:\n","          return 0\n","\n","      class_proportions = class_counts.float() / total_samples\n","      score = 1 - torch.std(class_proportions).item()\n","\n","      return score\n","\n","    def set_aggregation_methodology(self, methodology):\n","      self.aggregation_methodology = methodology\n","\n","    def get_final_scores(self):\n","\n","      \"\"\"\n","      Convert performance metrics lists into a pandas DataFrame.\n","\n","      Parameters:\n","      accuracy_scores (list): List of accuracy scores.\n","      precision_scores (list): List of precision scores.\n","      recall_scores (list): List of recall scores.\n","      f1_scores (list): List of F1 scores.\n","\n","      Returns:\n","      pd.DataFrame: DataFrame containing the metrics.\n","      \"\"\"\n","      # Create a dictionary from the lists\n","      metrics_dict = {\n","          'Accuracy': self.accuracy_scores,\n","          'Precision': self.precision_scores,\n","          'Recall': self.recall_scores,\n","          'F1 Score': self.f1_scores\n","      }\n","\n","      # Convert the dictionary into a DataFrame\n","      df = pd.DataFrame(metrics_dict)\n","\n","      return df\n","\n","    def get_accuracy_score(self):\n","      return self.current_accuracy\n","\n","    def set_accuracy_score(self, accuracy):\n","      self.current_accuracy = accuracy\n","\n","    def get_node_id(self):\n","      return self.node_id\n","\n","    def get_test_loader(self) -> DataLoader:\n","        \"\"\"\n","        Return the testing DataLoader.\n","\n","        Returns:\n","        DataLoader: The testing DataLoader.\n","        \"\"\"\n","        return self.test_loader\n","\n","    def broadcast_parameters(self):\n","      ##[Balance_Score, Weighting, Current_Accuracy]\n","        \"\"\"\n","        Return the model parameters.\n","\n","        Returns:\n","        dict: Dictionary of model parameters.\n","        \"\"\"\n","        # return self.model.state_dict()\n","        return_list = []\n","        for param in self.model.parameters():\n","          # print(str(param))\n","          return_list.append(param.clone())\n","\n","        return_list.insert(0, self.current_accuracy)\n","        return_list.insert(0, self.weighting)\n","        return_list.insert(0, self.balance_score)\n","\n","        return return_list\n","\n","\n","    def gather_parameters(self, params):\n","        print(\"Gathered Parameters for Node \" + str(self.node_id))\n","        self.global_parameters.append(params)\n","        print(\"Length of Gathered Parameters for Node \" + str(self.node_id) + \" : \" + str(len(self.global_parameters)))\n","\n","    def size_average_parameters(self):\n","          averaged_params = []\n","          print(\"Size of global params: \" + str(len(self.global_parameters)))\n","\n","          # Create a copy of global_parameters without modifying the original\n","          params = [param[:] for param in self.global_parameters]  # Shallow copy of each param list\n","          weightings = []\n","\n","          # Extract non-tensor elements without modifying the original\n","          for param_set in params:\n","              balance_score = param_set[0]  # Access without popping (no removal)\n","              weighting = param_set[1]      # Access weighting\n","              accuracy = param_set[2]       # Access accuracy\n","\n","              weightings.append(weighting)\n","\n","          # Clone the tensors and initialize averaged_params\n","          for param in params[0][3:]:  # Skip non-tensor elements (balance, weighting, accuracy)\n","              averaged_params.append(torch.zeros_like(param))  # Initialize with zeros\n","\n","          # Sum the parameters with their corresponding weights\n","          total_weight = 0\n","          for model_params, weight in zip(params, weightings):\n","              model_params = model_params[3:]  # Exclude non-tensor elements\n","              if len(model_params) != len(averaged_params):\n","                  raise ValueError(\"Mismatch in the number of parameters between models.\")\n","\n","              for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","                  if param.shape != avg_param.shape:\n","                      raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","                  averaged_params[i] += param * weight\n","              total_weight += weight\n","\n","          # Normalize by the total weight\n","          if total_weight > 0:\n","              for i in range(len(averaged_params)):\n","                  averaged_params[i] /= total_weight\n","\n","          return averaged_params\n","\n","\n","\n","\n","    def balance_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","\n","      # Create a shallow copy of the global parameters to avoid mutation\n","      params = [param[:] for param in self.global_parameters]  # Shallow copy of each param list\n","      balance_scores = []\n","\n","      # Extract non-tensor elements (balance scores, weightings, accuracy) without modifying the original\n","      for param_set in params:\n","          balance_score = param_set[0]  # Access balance score\n","          weighting = param_set[1]      # Access weighting (but not needed)\n","          accuracy = param_set[2]       # Access accuracy (but not needed)\n","          print(\"Balance Score: \" + str(balance_score))\n","          balance_scores.append(balance_score)\n","\n","      # Clone the tensors and initialize averaged_params with zeros\n","      for param in params[0][3:]:  # Skip first three elements (balance, weighting, accuracy)\n","          averaged_params.append(torch.zeros_like(param))  # Initialize with zeros\n","\n","      # Sum the parameters with their corresponding balance scores\n","      total_balance_scores = 0\n","      for model_params, balance_score in zip(params, balance_scores):\n","          model_params = model_params[3:]  # Exclude the first three non-tensor elements\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * balance_score\n","          total_balance_scores += balance_score\n","\n","      # Normalize by the total balance scores\n","      if total_balance_scores > 0:\n","          print(\"Total Balance Scores: \" + str(total_balance_scores))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_balance_scores\n","\n","      return averaged_params\n","\n","    def test_aggregation(self):\n","      size_model = copy.deepcopy(self.model)  # Make a copy of the model\n","      balance_model = copy.deepcopy(self.model)  # Make another copy of the model\n","      averaged_size_params = self.size_average_parameters()\n","      # size_model = self.model\n","      size_state_dict = dict(zip(size_model.state_dict().keys(), averaged_size_params))\n","      size_model.load_state_dict(size_state_dict)\n","\n","      averaged_balance_params = self.balance_average_parameters()\n","      # balance_model = self.model\n","      balance_state_dict = dict(zip(balance_model.state_dict().keys(), averaged_balance_params))\n","      balance_model.load_state_dict(balance_state_dict)\n","\n","      size_accuracy, size_precision, size_recall, size_f1 = evaluate(size_model, self.test_loader)\n","      balance_accuracy, balance_precision, balance_recall, balance_f1 = evaluate(balance_model, self.test_loader)\n","\n","      print(\"Size Accuracy: \" + str(size_accuracy))\n","      print(\"Balance Accuracy: \" + str(balance_accuracy))\n","      if size_accuracy > balance_accuracy:\n","        return \"size\"\n","      else:\n","        return \"balance\"\n","\n","\n","\n","    def aggregate_parameters(self):\n","      if self.aggregation_methodology == \"size_average\":\n","        averaged_params = self.size_average_parameters()\n","      elif self.aggregation_methodology == \"balance_average\":\n","        averaged_params = self.balance_average_parameters()\n","      else:\n","        raise ValueError(\"Invalid aggregation methodology. Use 'average' or 'size_average' or 'accuracy_average'.\")\n","\n","      print(\"Length of Averaged Params for node \" + str(self.node_id) + \" : \" + str(len(averaged_params)))\n","      self.set_parameters(averaged_params)\n","\n","      self.global_parameters = []\n","\n","\n","    def set_parameters(self, parameters):\n","\n","        \"\"\"\n","        Set the model parameters.\n","\n","        Parameters:\n","        parameters (dict): Dictionary of model parameters.\n","        \"\"\"\n","        # Convert the list of averaged parameters back into the correct format for the model\n","        print(\"Setting Parameters for node: \" + str(self.node_id))\n","        new_state_dict = dict(zip(self.model.state_dict().keys(), parameters))\n","        self.model.load_state_dict(new_state_dict)\n","        print(\"Set Parameters for node \" + str(self.node_id))\n","\n","\n","\n","    def train(self):\n","      # Move model to the specified device\n","      self.model.to(device)\n","\n","      for epoch in range(NUM_LOCAL_EPOCHS):\n","\n","        self.model.train()\n","        running_loss = 0.0\n","\n","        for images, labels in self.__train_loader:\n","            # Move images and labels to the specified device\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Flatten the labels tensor to be 1D\n","            if len(labels.shape) == 2:\n","                labels = labels.squeeze(1)  # Remove the extra dimension\n","\n","            # Check for label values out of bounds\n","            if labels.max() >= 4:\n","                raise ValueError(f\"Label value {labels.max()} is out of bounds for the number of classes {4}.\")\n","\n","            # Ensure labels are 1D\n","            if len(labels.shape) != 1:\n","                raise ValueError(\"Labels tensor is not 1D. It should be of shape [batch_size].\")\n","\n","            self.optimizer.zero_grad()\n","            outputs = self.model(images)\n","\n","            # Ensure labels are of type long\n","            labels = labels.long()\n","\n","            loss = self.criterion(outputs, labels)\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            running_loss += loss.item()\n","      # Print the average loss for this epoch\n","        print(f\"Epoch [{epoch+1}/{NUM_LOCAL_EPOCHS}], Training Loss: {running_loss / len(self.__train_loader)}\")\n","\n","\n","\n","\n","    def evaluate(self):\n","        self.model.eval()  # Set the model to evaluation mode\n","\n","        all_labels = []\n","        all_predictions = []\n","\n","        with torch.no_grad():  # No need to calculate gradients during evaluation\n","            for images, labels in self.test_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = self.model(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                all_labels.extend(labels.cpu().numpy())\n","                all_predictions.extend(predicted.cpu().numpy())\n","\n","        # Convert lists to numpy arrays for sklearn metrics\n","        all_labels = np.array(all_labels).flatten()\n","        all_predictions = np.array(all_predictions)\n","\n","        # Calculate metrics\n","        accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","        precision = precision_score(all_labels, all_predictions, average='weighted')\n","        recall = recall_score(all_labels, all_predictions, average='weighted')\n","        f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","        self.accuracy_scores.append(accuracy)\n","        self.precision_scores.append(precision)\n","        self.recall_scores.append(recall)\n","        self.f1_scores.append(f1)\n","        self.set_accuracy_score(accuracy)\n","        return accuracy, precision, recall, f1\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qK8K79a2NKnM"},"outputs":[],"source":["def train_and_communicate(node, nodes):\n","    node.train()\n","    metrics = node.evaluate()\n","    print(\"Metrics for Node \" + str(node.get_node_id()) + \" : \" + str(metrics))\n","    # Send parameters to all other nodes\n","    for other_node in nodes:\n","      other_node.gather_parameters(node.broadcast_parameters())\n","      print(\"NODE \" + str(node.get_node_id()) + \"  HAS BROADCASTED \")\n","\n","    return"]},{"cell_type":"code","source":["def dynamic_aggregation(nodes):\n","  decisions = []\n","  for node in nodes:\n","    decisions.append(node.test_aggregation())\n","  if decisions.count(\"size\") > decisions.count(\"balance\"):\n","    for node in nodes:\n","      node.set_aggregation_methodology(\"size_average\")\n","    return \"size\"\n","  elif decisions.count(\"size\") < decisions.count(\"balance\"):\n","    for node in nodes:\n","      node.set_aggregation_methodology(\"balance_average\")\n","    return \"balance\"\n","  else:\n","    for node in nodes:\n","      node.set_aggregation_methodology(\"balance_average\")\n","\n","    return \"balance\""],"metadata":{"id":"psm3xtAXvEC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUE36X0v1pyp"},"outputs":[],"source":["def evaluate(model, test_loader):\n","  model.eval()  # Set the model to evaluation mode\n","\n","  all_labels = []\n","  all_predictions = []\n","\n","  with torch.no_grad():  # No need to calculate gradients during evaluation\n","      for images, labels in test_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          all_labels.extend(labels.cpu().numpy())\n","          all_predictions.extend(predicted.cpu().numpy())\n","\n","  # Convert lists to numpy arrays for sklearn metrics\n","  all_labels = np.array(all_labels).flatten()\n","  all_predictions = np.array(all_predictions)\n","\n","    # Print the shapes of the arrays\n","  print(f\"Shape of all_labels: {all_labels.shape}\")\n","  print(f\"Shape of all_predictions: {all_predictions.shape}\")\n","\n","\n","  print(f\"Unique labels: {np.unique(all_labels)}\")\n","  print(f\"Unique predictions: {np.unique(all_predictions)}\")\n","\n","\n","  print(f\"Sample Labels: {all_labels[:10]}\")\n","  print(f\"Sample Predictions: {all_predictions[:10]}\")\n","\n","  print(\"Num Correct: \" + str(np.sum(all_predictions == all_labels)))\n","\n","  # Calculate metrics\n","  accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","  precision = precision_score(all_labels, all_predictions, average='weighted')\n","  recall = recall_score(all_labels, all_predictions, average='weighted')\n","  f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","  return accuracy, precision, recall, f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtHShANb18kl"},"outputs":[],"source":["# Function to write the metrics to a CSV file\n","def write_metrics_to_csv(filename, metrics_list):\n","    file_exists = os.path.isfile(filename)\n","\n","    with open(filename, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","\n","        # Write the header only if the file is being created\n","        if not file_exists:\n","            writer.writerow(['Aggregation Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n","\n","        # Write the data\n","        writer.writerow(metrics_list)\n","\n","    print(f'Metrics written to {filename}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HVY_x9mNP_r"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","for i in range(30):\n","    dataset, testing_set, num_classes = load_data()\n","\n","    #split data into final testing and data for nodes\n","    subsets, dataset, weightings = split_data_nodes(dataset, NUM_NODES)\n","\n","    #create the final test loader and set it\n","    final_test_loader = create_final_data_test_loader(testing_set)\n","\n","\n","    nodes = []\n","    for i in range(0,NUM_NODES):\n","      train_loader, val_loader =  create_data_loaders(subsets[i])\n","      node = Node(i, train_loader, val_loader, weightings[i], \"balance_average\")\n","      nodes.append(node)\n","\n","    winners = []\n","    # Training and aggregation process\n","    for _ in range(NUM_GLOBAL_EPOCHS):  # Number of training rounds\n","        print(\"Round \" + str(_))\n","        with concurrent.futures.ThreadPoolExecutor() as executor:\n","            executor.map(train_and_communicate, nodes, [nodes]*len(nodes))\n","            # print(\"hello\")\n","\n","        if _ < NUM_GLOBAL_EPOCHS / 2:\n","            winner = dynamic_aggregation(nodes)\n","            winners.append(winner)\n","            print(\"Winners: \" + str(winners))\n","        else:\n","            winner = max(set(winners), key=winners.count)\n","            print(\"Winner: \" + str(winner))\n","            if winner == \"size\":\n","                for node in nodes:\n","                    node.set_aggregation_methodology(\"size_average\")\n","            elif winner == \"balance\":\n","                for node in nodes:\n","                    node.set_aggregation_methodology(\"balance_average\")\n","            else:\n","              print(\"MAJOR ERROR: Winner is in fact: \" + str(winner))\n","\n","\n","        # Aggregation phase\n","        for node in nodes:\n","          updated_params = node.aggregate_parameters()\n","\n","        time.sleep(1)  # Simulate time between rounds\n","\n","\n","    node = nodes[0]\n","    accuracy, precision, recall, f1 = evaluate(node.get_model(), final_test_loader)\n","    filename = '/content/drive/My Drive/Swarm_Learning/dynamic_bloodcancer2.csv'\n","    metrics_list = [accuracy, precision, recall, f1]\n","    write_metrics_to_csv(filename, metrics_list)\n","\n","\n","\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO5k400vzmfKxL+92efEDvc"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}