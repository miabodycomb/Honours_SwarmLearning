{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4f2QMSAX4h9p","collapsed":true},"outputs":[],"source":["!pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWhVdMYWiPhe"},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from torchvision import datasets, transforms\n","from torchvision.models import mobilenet_v2\n","import sklearn\n","from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset, Dataset\n","from torchvision.datasets.folder import default_loader\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import os\n","from google.colab import drive\n","import concurrent.futures\n","import time\n","import random\n","import csv\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","from torch.optim import AdamW\n","import timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7kqCkRdibcHu"},"outputs":[],"source":["# Mount Google Drive for persistent storage\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yTUlgE767jNL"},"outputs":[],"source":["NUM_NODES = 1\n","NUM_GLOBAL_EPOCHS = 5\n","NUM_LOCAL_EPOCHS = 5\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TNUYGvn7kud"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, root_dirs, class_labels, transform=None):\n","        self.transform = transform\n","        self.samples = []\n","        self.labels = set()  # Used to store unique tag sets\n","\n","        # Loop through each category's directory and read the files\n","        for i, dirs in enumerate(root_dirs):\n","            for dir_path in dirs:\n","                for img_name in os.listdir(dir_path):\n","                    img_path = os.path.join(dir_path, img_name)\n","                    self.samples.append((img_path, i))  # Use index as label\n","                    self.labels.add(class_labels[i])\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","    def __getitem__(self, index):\n","        path, label = self.samples[index]\n","        sample = default_loader(path)\n","        if self.transform is not None:\n","            sample = self.transform(sample)\n","        return sample, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yrCHf9ofShkM"},"outputs":[],"source":["def load_data():\n","    transform = transforms.Compose([\n","        transforms.Resize((256, 256)),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomRotation(20),\n","        transforms.RandomResizedCrop(224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","    ])\n","\n","    # Use the CustomDataset\n","    root_dirs = [\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/Benign'],\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/[Malignant] Pre-B'],\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/[Malignant] Pro-B'],\n","    ['/content/drive/My Drive/Swarm_Learning/Data/Blood cell Cancer [ALL]/[Malignant] early Pre-B']\n","    ]\n","    class_labels = ['Benign', 'Malignant_Pre-B', 'Malignant_Pro-B', 'Malignant_early Pre-B']\n","    dataset = CustomDataset(root_dirs, class_labels, transform=transform)\n","    num_classes = len(dataset.labels)\n","    print(\"Number of samples in the dataset:\", len(dataset))\n","    print(\"Detected number of classes:\", num_classes)\n","\n","    # Split the dataset into training and testing sets (80% train, 20% test)\n","    train_size = int(0.8 * len(dataset))\n","    test_size = len(dataset) - train_size\n","    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","    return train_dataset, test_dataset, num_classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m3QDUXPs7nSE"},"outputs":[],"source":["def split_data_nodes(dataset, num_nodes):\n","  # Determine the sizes of each split\n","  dataset_size = len(dataset)\n","  indices = list(range(dataset_size))\n","  np.random.shuffle(indices)\n","\n","  split_sizes = np.random.randint(1, dataset_size // num_nodes + 1, size=num_nodes - 1)\n","  split_sizes = np.append(split_sizes, dataset_size - split_sizes.sum())\n","  np.random.shuffle(split_sizes)\n","\n","  # Create random splits\n","  subsets = []\n","  start = 0\n","  for size in split_sizes:\n","      subset_indices = indices[start:start + size]\n","      subsets.append(subset_indices)\n","      start += size\n","\n","\n","  # Apply the splits to the dataset\n","  dataset_splits = [torch.utils.data.Subset(dataset, subset) for subset in subsets]\n","\n","  # Calculate the size weightings for each subset\n","  weightings = [len(subset) / dataset_size for subset in dataset_splits]\n","\n","\n","\n","  print(\"Data has been split into \" + str(num_nodes) + \" nodes\")\n","  # Print the size of each data subset\n","  for i, subset in enumerate(dataset_splits):\n","      print(f'Size of subset {i+1}: {len(subset)}')\n","\n","\n","  return dataset_splits, dataset, weightings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BkMLI52P7pK7"},"outputs":[],"source":["def create_data_loaders(subset):\n","    # Split into train and validation (adjust validation split as needed)\n","    val_size = int(0.2 * len(subset))\n","    train_size = len(subset) - val_size\n","    train_subset, val_subset = torch.utils.data.random_split(subset, [train_size, val_size])\n","\n","    train_loader = torch.utils.data.DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = torch.utils.data.DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    print(\"Data Loader Created\")\n","    return train_loader, val_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssUtfq0gXqN4"},"outputs":[],"source":["class SwinTransformerModel(nn.Module):\n","    def __init__(self, num_classes=4):\n","        super(SwinTransformerModel, self).__init__()\n","        self.swin_transformer = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)\n","\n","        # Freeze all parameters of the pre-trained model\n","        for param in self.swin_transformer.parameters():\n","            param.requires_grad = False\n","\n","        # Get the number of input features for the last layer\n","        num_features = self.swin_transformer.head.in_features\n","        self.swin_transformer.head = nn.Sequential(\n","            nn.Dropout(0.5),  # Adding Dropout Layers to Reduce Overfitting\n","            nn.Linear(num_features, 512),  # Top level fully connected layer\n","            nn.ReLU(),  # Activation function\n","            nn.Linear(512, num_classes)  # Output layer\n","        )\n","\n","        # Ensure that only the parameters of the newly added fully connected layer are updated\n","        for param in self.swin_transformer.head.parameters():\n","            param.requires_grad = True\n","\n","        for name, param in self.swin_transformer.named_parameters():\n","            if name in ['layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias']:\n","                param.requires_grad = True\n","\n","        # Add a global average pooling layer to handle the spatial dimensions\n","        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n","\n","    def forward(self, x):\n","        x = self.swin_transformer.forward_features(x)  # Extract features\n","\n","        # Adjust the dimension order\n","        x = x.permute(0, 3, 1, 2)  # From [32, 7, 7, 768] to [32, 768, 7, 7]\n","\n","        # Apply global average pooling\n","        x = self.global_avg_pool(x)  # From [32, 768, 7, 7] to [32, 768, 1, 1]\n","\n","        x = torch.flatten(x, 1)  # Flatten from [32, 768, 1, 1] to [32, 768]\n","        x = self.swin_transformer.head(x)  # Apply fully connected layer\n","\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjzhD9GP8T7H"},"outputs":[],"source":["def create_final_data_test_loader(final_testing):\n","  final_model_test_loader = torch.utils.data.DataLoader(final_testing, batch_size=BATCH_SIZE, shuffle=False)\n","  return final_model_test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYvQtkbxcDBU"},"outputs":[],"source":["def model_parameters_to_string(model):\n","    params_str = \"Model Parameters:\\n\"\n","    for name, param in model.named_parameters():\n","        params_str += f\"Name: {name}, Shape: {param.shape}\\n\"\n","        params_str += f\"{param.data}\\n\"\n","        params_str += \"-\" * 50 + \"\\n\"\n","    return params_str"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6waIo5ZS7rh-"},"outputs":[],"source":["\n","class Node:\n","    def __init__(self, node_id, train_loader: DataLoader, test_loader: DataLoader, weighting, aggregation_methodology):\n","        \"\"\"\n","        Initialize the Node with training and testing DataLoaders.\n","\n","        Parameters:\n","        train_loader (DataLoader): DataLoader for training data.\n","        test_loader (DataLoader): DataLoader for testing data.\n","        \"\"\"\n","        self.__train_loader = train_loader\n","        self.test_loader = test_loader\n","        self.node_id = node_id\n","        self.global_parameters = []\n","        self.accuracy = None\n","        self.model = SwinTransformerModel() ##num_classes = 4\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.optimizer = optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=0.01)\n","        self.accuracy_scores = []\n","        self.current_accuracy = 0\n","        self.accuracy_scores = []\n","        self.f1_scores = []\n","        self.precision_scores = []\n","        self.recall_scores = []\n","        self.weighting = weighting\n","        self.aggregation_methodology = aggregation_methodology\n","        self.balance_score = self.get_balance_score()\n","\n","    def get_model(self):\n","      return self.model\n","\n","    def get_balance_score(self):\n","        class_counts = np.zeros(4, dtype=int)  # 4 classes\n","        for _, label in self.__train_loader:\n","            class_counts[label] += 1\n","        total_samples = sum(class_counts)\n","        if total_samples == 0:\n","            return 0\n","        class_proportions = np.array(class_counts) / total_samples\n","        score = 1 - np.std(class_proportions)\n","        return score\n","\n","    def get_final_scores(self):\n","\n","      \"\"\"\n","      Convert performance metrics lists into a pandas DataFrame.\n","\n","      Parameters:\n","      accuracy_scores (list): List of accuracy scores.\n","      precision_scores (list): List of precision scores.\n","      recall_scores (list): List of recall scores.\n","      f1_scores (list): List of F1 scores.\n","\n","      Returns:\n","      pd.DataFrame: DataFrame containing the metrics.\n","      \"\"\"\n","      # Create a dictionary from the lists\n","      metrics_dict = {\n","          'Accuracy': self.accuracy_scores,\n","          'Precision': self.precision_scores,\n","          'Recall': self.recall_scores,\n","          'F1 Score': self.f1_scores\n","      }\n","\n","      # Convert the dictionary into a DataFrame\n","      df = pd.DataFrame(metrics_dict)\n","\n","      return df\n","\n","    def get_accuracy_score(self):\n","      return self.current_accuracy\n","\n","    def set_accuracy_score(self, accuracy):\n","      self.current_accuracy = accuracy\n","\n","    def get_node_id(self):\n","      return self.node_id\n","\n","    def get_test_loader(self) -> DataLoader:\n","        \"\"\"\n","        Return the testing DataLoader.\n","\n","        Returns:\n","        DataLoader: The testing DataLoader.\n","        \"\"\"\n","        return self.test_loader\n","\n","    def broadcast_parameters(self):\n","        \"\"\"\n","        Return the model parameters.\n","\n","        Returns:\n","        dict: Dictionary of model parameters.\n","        \"\"\"\n","        return_list = []\n","        for param in self.model.parameters():\n","          return_list.append(param.clone())\n","\n","        return_list.insert(0, self.current_accuracy)\n","        return_list.insert(0, self.weighting)\n","        return_list.insert(0, self.balance_score)\n","\n","        return return_list\n","\n","\n","    def gather_parameters(self, params):\n","        print(\"Gathered Parameters for Node \" + str(self.node_id))\n","        self.global_parameters.append(params)\n","        print(\"Length of Gathered Parameters for Node \" + str(self.node_id) + \" : \" + str(len(self.global_parameters)))\n","\n","    def average_parameters(self):\n","      # Initialize a list to store the summed parameters\n","      averaged_params = []\n","\n","      params = self.global_parameters\n","      for inner_list in params:\n","        inner_list.pop(0)\n","        inner_list.pop(0)\n","        inner_list.pop(0)\n","      # Iterate over the parameters of the first model to initialize the structure of the average\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","      # Sum the parameters from each model\n","      for model_params in params:\n","          for i, param in enumerate(model_params):\n","              averaged_params[i] += param\n","\n","      # Divide by the number of models to get the average\n","      num_models = len(params)\n","      for i in range(len(averaged_params)):\n","          averaged_params[i] /= num_models\n","\n","      return averaged_params\n","\n","\n","    def size_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      weightings = []\n","\n","      for param in params:\n","        param.pop(0) ##Remove balance Score\n","        weighting = param.pop(0) ##Get weighting\n","        param.pop(0) ## Remove accuracy score\n","        weightings.append(weighting)\n","\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","      # Sum the parameters with their corresponding weights\n","      total_weight = 0\n","      for model_params, weight in zip(params, weightings):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * weight\n","          total_weight += weight\n","\n","      # Normalize by the total weight\n","      if total_weight > 0:\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_weight\n","\n","      return averaged_params\n","\n","\n","\n","    def accuracy_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      accuracies = []\n","\n","      for param in params:\n","        param.pop(0) ##Get rid of balance score\n","        param.pop(0) ##Get rid of Weighting\n","        accuracy = param.pop(0)\n","        print(\"Accuracy: \" + str(accuracy))\n","        accuracies.append(accuracy)\n","\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","          # Sum the parameters with their corresponding weights\n","      total_accuracies = 0\n","      for model_params, accuracy in zip(params, accuracies):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * accuracy\n","          total_accuracies += accuracy\n","\n","      # Normalize by the total weight\n","      if total_accuracies > 0:\n","          print(\"Total Accuracy: \" + str(total_accuracies))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_accuracies\n","\n","      return averaged_params\n","\n","    def selective_accuracy_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      accuracies = []\n","\n","      for param in params:\n","        param.pop(0) ##Get rid of balance score\n","        param.pop(0) ##Get rid of Weighting\n","        accuracy = param.pop(0)\n","        print(\"Accuracy: \" + str(accuracy))\n","        accuracies.append(accuracy)\n","\n","      # Identify the index of the node with the lowest accuracy\n","      min_accuracy_index = accuracies.index(min(accuracies))\n","          # Exclude the parameters of the node with the lowest accuracy\n","      filtered_params = [p for i, p in enumerate(params) if i != min_accuracy_index]\n","      filtered_accuracies = [a for i, a in enumerate(accuracies) if i != min_accuracy_index]\n","\n","      # Check if we have remaining nodes after exclusion\n","      if not filtered_params:\n","          raise ValueError(\"No parameters left to average after excluding the lowest accuracy node.\")\n","\n","      # Initialize averaged_params with zeros\n","      for param in filtered_params[0]:\n","          averaged_params.append(torch.zeros_like(param))\n","\n","      # Sum the parameters with their corresponding weights\n","      total_accuracies = 0\n","      for model_params, accuracy in zip(filtered_params, filtered_accuracies):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * accuracy\n","          total_accuracies += accuracy\n","\n","      # Normalize by the total weight\n","      if total_accuracies > 0:\n","          print(\"Total Accuracy: \" + str(total_accuracies))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_accuracies\n","\n","      return averaged_params\n","\n","\n","    def balance_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      balance_scores = []\n","\n","      for param in params:\n","        balance_score = param.pop(0) ##Store balance score\n","        param.pop(0) ##Get rid of Weighting\n","        param.pop(0) ##Get rid of Accuracy\n","        print(\"Balance Score: \" + str(balance_score))\n","        balance_scores.append(balance_score)\n","\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","      # Sum the parameters with their corresponding weights\n","      total_balance_scores = 0\n","      for model_params, balance_score in zip(params, balance_scores):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * balance_score\n","          total_balance_scores += balance_score\n","\n","      # Normalize by the total weight\n","      if total_balance_scores > 0:\n","          print(\"Total Balance Scores: \" + str(total_balance_scores))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_balance_scores\n","\n","      return averaged_params\n","\n","\n","\n","\n","    def aggregate_parameters(self):\n","      if self.aggregation_methodology == \"average\":\n","        averaged_params = self.average_parameters()\n","      elif self.aggregation_methodology == \"size_average\":\n","        averaged_params = self.size_average_parameters()\n","      elif self.aggregation_methodology == \"accuracy_average\":\n","        averaged_params = self.accuracy_average_parameters()\n","      elif self.aggregation_methodology == \"balance_average\":\n","        averaged_params = self.balance_average_parameters()\n","      elif self.aggregation_methodology == \"selective_accuracy_average\":\n","        averaged_params = self.selective_accuracy_average_parameters()\n","      else:\n","        raise ValueError(\"Invalid aggregation methodology. Use 'average' or 'size_average' or 'accuracy_average'.\")\n","      print(\"Length of Averaged Params for node \" + str(self.node_id) + \" : \" + str(len(averaged_params)))\n","      self.set_parameters(averaged_params)\n","\n","      self.global_parameters = []\n","\n","\n","    def set_parameters(self, parameters):\n","\n","        \"\"\"\n","        Set the model parameters.\n","\n","        Parameters:\n","        parameters (dict): Dictionary of model parameters.\n","        \"\"\"\n","        # Convert the list of averaged parameters back into the correct format for the model\n","        print(\"Setting Parameters for node: \" + str(self.node_id))\n","        new_state_dict = dict(zip(self.model.state_dict().keys(), parameters))\n","        self.model.load_state_dict(new_state_dict)\n","        print(\"Set Parameters for node \" + str(self.node_id))\n","\n","\n","\n","    def train(self):\n","      # Move model to the specified device\n","      self.model.to(device)\n","\n","      for epoch in range(NUM_LOCAL_EPOCHS):\n","\n","        self.model.train()\n","        running_loss = 0.0\n","\n","        for images, labels in self.__train_loader:\n","            # Move images and labels to the specified device\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Flatten the labels tensor to be 1D\n","            if len(labels.shape) == 2:\n","                labels = labels.squeeze(1)  # Remove the extra dimension\n","\n","            # Check for label values out of bounds\n","            if labels.max() >= 4:\n","                raise ValueError(f\"Label value {labels.max()} is out of bounds for the number of classes {4}.\")\n","\n","            # Ensure labels are 1D\n","            if len(labels.shape) != 1:\n","                raise ValueError(\"Labels tensor is not 1D. It should be of shape [batch_size].\")\n","\n","            self.optimizer.zero_grad()\n","            outputs = self.model(images)\n","\n","            # Ensure labels are of type long\n","            labels = labels.long()\n","\n","            loss = self.criterion(outputs, labels)\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            running_loss += loss.item()\n","      # Print the average loss for this epoch\n","        print(f\"Epoch [{epoch+1}/{NUM_LOCAL_EPOCHS}], Training Loss: {running_loss / len(self.__train_loader)}\")\n","\n","\n","\n","\n","    def evaluate(self):\n","        self.model.eval()  # Set the model to evaluation mode\n","\n","        all_labels = []\n","        all_predictions = []\n","\n","        with torch.no_grad():  # No need to calculate gradients during evaluation\n","            for images, labels in self.test_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = self.model(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                all_labels.extend(labels.cpu().numpy())\n","                all_predictions.extend(predicted.cpu().numpy())\n","\n","        # Convert lists to numpy arrays for sklearn metrics\n","        all_labels = np.array(all_labels).flatten()\n","        all_predictions = np.array(all_predictions)\n","\n","        # Calculate metrics\n","        accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","        precision = precision_score(all_labels, all_predictions, average='weighted')\n","        recall = recall_score(all_labels, all_predictions, average='weighted')\n","        f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","        self.accuracy_scores.append(accuracy)\n","        self.precision_scores.append(precision)\n","        self.recall_scores.append(recall)\n","        self.f1_scores.append(f1)\n","        self.set_accuracy_score(accuracy)\n","        return accuracy, precision, recall, f1\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qK8K79a2NKnM"},"outputs":[],"source":["def train_and_communicate(node, nodes):\n","    # Train the node\n","    node.train()\n","    print(\"HELLO\")\n","    metrics = node.evaluate()\n","    print(\"Metrics for Node \" + str(node.get_node_id()) + \" : \" + str(metrics))\n","    # Send parameters to all other nodes\n","    for other_node in nodes:\n","      other_node.gather_parameters(node.broadcast_parameters())\n","      print(\"NODE \" + str(node.get_node_id()) + \"  HAS BROADCASTED \")\n","\n","    return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUE36X0v1pyp"},"outputs":[],"source":["def evaluate(model, test_loader):\n","  model.eval()  # Set the model to evaluation mode\n","\n","  all_labels = []\n","  all_predictions = []\n","\n","  with torch.no_grad():  # No need to calculate gradients during evaluation\n","      for images, labels in test_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          all_labels.extend(labels.cpu().numpy())\n","          all_predictions.extend(predicted.cpu().numpy())\n","\n","  # Convert lists to numpy arrays for sklearn metrics\n","  all_labels = np.array(all_labels).flatten()\n","  all_predictions = np.array(all_predictions)\n","\n","  # Print the shapes of the arrays\n","  print(f\"Shape of all_labels: {all_labels.shape}\")\n","  print(f\"Shape of all_predictions: {all_predictions.shape}\")\n","\n","\n","  print(f\"Unique labels: {np.unique(all_labels)}\")\n","  print(f\"Unique predictions: {np.unique(all_predictions)}\")\n","\n","\n","  print(f\"Sample Labels: {all_labels[:10]}\")\n","  print(f\"Sample Predictions: {all_predictions[:10]}\")\n","\n","  print(\"Num Correct: \" + str(np.sum(all_predictions == all_labels)))\n","\n","  # Calculate metrics\n","  accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","  precision = precision_score(all_labels, all_predictions, average='weighted')\n","  recall = recall_score(all_labels, all_predictions, average='weighted')\n","  f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","  return accuracy, precision, recall, f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtHShANb18kl"},"outputs":[],"source":["# Function to write the metrics to a CSV file\n","def write_metrics_to_csv(filename, metrics_list):\n","    file_exists = os.path.isfile(filename)\n","\n","    with open(filename, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","\n","        # Write the header only if the file is being created\n","        if not file_exists:\n","            writer.writerow(['Aggregation Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n","\n","        # Write the data\n","        writer.writerow(metrics_list)\n","\n","    print(f'Metrics written to {filename}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6HVY_x9mNP_r"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","aggregation_methodologies = ['average', 'size_average', 'balance_average', 'accuracy_average', 'selective_accuracy_average']\n","# aggregation_methodology = 'balance_average'\n","for aggregation_methodology in aggregation_methodologies:\n","  print(\"Aggregation Methodology: \" + aggregation_methodology)\n","  for i in range(30):\n","\n","      dataset, testing_set, num_classes = load_data()\n","\n","      #split data into final testing and data for nodes\n","      subsets, dataset, weightings = split_data_nodes(dataset, 4)\n","\n","      #create the final test loader and set it\n","      final_test_loader = create_final_data_test_loader(testing_set)\n","\n","      nodes = []\n","      for i in range(0,NUM_NODES):\n","        train_loader, val_loader =  create_data_loaders(subsets[i])\n","        node = Node(i, train_loader, val_loader, weightings[i], aggregation_methodology)\n","        nodes.append(node)\n","\n","\n","      # Training and aggregation process\n","      for _ in range(NUM_GLOBAL_EPOCHS):  # Number of training rounds\n","          print(\"Round \" + str(_))\n","          with concurrent.futures.ThreadPoolExecutor() as executor:\n","              executor.map(train_and_communicate, nodes, [nodes]*len(nodes))\n","\n","          # Aggregation phase\n","          for node in nodes:\n","            updated_params = node.aggregate_parameters()\n","\n","          time.sleep(1)  # Simulate time between rounds\n","\n","\n","      node = nodes[0]\n","      accuracy, precision, recall, f1 = evaluate(node.get_model(), final_test_loader)\n","      filename = '/content/drive/My Drive/Swarm_Learning/bloodcancer.csv'\n","      metrics_list = [aggregation_methodology, accuracy, precision, recall, f1]\n","      write_metrics_to_csv(filename, metrics_list)\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyM0yfOy/upCQHGl/+VMCSqY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}