{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6234,"status":"ok","timestamp":1729468473381,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"},"user_tz":-660},"id":"siQdg4qXy_7i","outputId":"1035ca6a-b75b-4989-edac-76e2286e8814"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting medmnist\n","  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.26.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.24.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.66.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (10.4.0)\n","Collecting fire (from medmnist)\n","  Downloading fire-0.7.0.tar.gz (87 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/87.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m81.9/87.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.4.1+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.1+cu121)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.5.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2024.2)\n","Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.13.1)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.4.1)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.35.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2024.9.20)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (24.1)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2024.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (3.0.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n","Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=faf388534fb26a1b7603aadf57b9145d9c0b94149c15f3bf4a0423e0ce7da405\n","  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n","Successfully built fire\n","Installing collected packages: fire, medmnist\n","Successfully installed fire-0.7.0 medmnist-3.0.2\n"]}],"source":["!pip install medmnist"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LWhVdMYWiPhe","executionInfo":{"status":"ok","timestamp":1729468485914,"user_tz":-660,"elapsed":12536,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["import torch\n","import numpy as np\n","import pandas as pd\n","from torchvision import datasets, transforms\n","import sklearn\n","from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","import os\n","from collections import Counter\n","from google.colab import drive\n","import concurrent.futures\n","import time\n","import random\n","from medmnist import BloodMNIST\n","import csv\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18487,"status":"ok","timestamp":1729468504399,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"},"user_tz":-660},"id":"7kqCkRdibcHu","outputId":"0dbf74bf-bc2c-4f5f-8e91-506d7e31f0d6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive for persistent storage\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"yTUlgE767jNL","executionInfo":{"status":"ok","timestamp":1729468504399,"user_tz":-660,"elapsed":9,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["NUM_NODES = 1\n","NUM_GLOBAL_EPOCHS = 5\n","NUM_LOCAL_EPOCHS = 5\n","train_size = 0.9\n","test_size = 0.1\n","BATCH_SIZE = 64\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"5TNUYGvn7kud","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":10,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["def load_data():\n","\n","  # Define the transformations\n","  transform = transforms.Compose([\n","      transforms.Resize((256, 256)),  # Resize to match the input size of the model\n","      transforms.ToTensor(),  # Convert images to tensor\n","      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize\n","  ])\n","\n","  test_dataset = BloodMNIST(split=\"test\", download=True, transform=transform)\n","  train_dataset = BloodMNIST(split=\"train\", download=True, transform=transform)\n","\n","\n","  print(\"Data has been loaded\")\n","  return train_dataset, test_dataset\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"m3QDUXPs7nSE","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":9,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["def split_data_nodes(dataset, num_nodes):\n","  # Determine the sizes of each split\n","  dataset_size = len(dataset)\n","  indices = list(range(dataset_size))\n","  np.random.shuffle(indices)\n","\n","  split_sizes = np.random.randint(1, dataset_size // num_nodes + 1, size=num_nodes - 1)\n","  split_sizes = np.append(split_sizes, dataset_size - split_sizes.sum())\n","  np.random.shuffle(split_sizes)\n","\n","  # Create random splits\n","  subsets = []\n","  start = 0\n","  for size in split_sizes:\n","      subset_indices = indices[start:start + size]\n","      subsets.append(subset_indices)\n","      start += size\n","\n","\n","  # Apply the splits to the dataset\n","  dataset_splits = [torch.utils.data.Subset(dataset, subset) for subset in subsets]\n","\n","  # Calculate the size weightings for each subset\n","  weightings = [len(subset) / dataset_size for subset in dataset_splits]\n","\n","\n","\n","  print(\"Data has been split into \" + str(num_nodes) + \" nodes\")\n","  # Print the size of each data subset\n","  for i, subset in enumerate(dataset_splits):\n","      print(f'Size of subset {i+1}: {len(subset)}')\n","\n","\n","  return dataset_splits, dataset, weightings"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"BkMLI52P7pK7","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":9,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["def create_data_loaders(subset):\n","\n","    # Split into train and validation (adjust validation split as needed)\n","    val_size = int(0.2 * len(subset))\n","    train_size = len(subset) - val_size\n","    train_subset, val_subset = torch.utils.data.random_split(subset, [train_size, val_size])\n","\n","    train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","\n","    print(\"Data Loader Created\")\n","    return train_loader, val_loader"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"l3iwOOHh8N9k","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":9,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["class SimpleNN(nn.Module):\n","    def __init__(self, input_size=256*256*3, num_classes=8):\n","        super(SimpleNN, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 128)\n","        self.fc2 = nn.Linear(128, num_classes)  # Ensure num_classes matches dataset\n","\n","    def forward(self, x):\n","        x = x.view(-1, 256*256*3)  # Flatten the image\n","        x = torch.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"WjzhD9GP8T7H","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":9,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["def create_final_data_test_loader(final_testing):\n","  final_model_test_loader = torch.utils.data.DataLoader(final_testing, batch_size=BATCH_SIZE, shuffle=False)\n","  return final_model_test_loader"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"gYvQtkbxcDBU","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":8,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["def model_parameters_to_string(model):\n","    params_str = \"Model Parameters:\\n\"\n","    for name, param in model.named_parameters():\n","        params_str += f\"Name: {name}, Shape: {param.shape}\\n\"\n","        params_str += f\"{param.data}\\n\"\n","        params_str += \"-\" * 50 + \"\\n\"\n","    return params_str"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"id":"6waIo5ZS7rh-","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":8,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["class Node:\n","    def __init__(self, node_id, train_loader: DataLoader, test_loader: DataLoader, weighting, aggregation_methodology):\n","        \"\"\"\n","        Initialize the Node with training and testing DataLoaders.\n","\n","        Parameters:\n","        train_loader (DataLoader): DataLoader for training data.\n","        test_loader (DataLoader): DataLoader for testing data.\n","        \"\"\"\n","        self.__train_loader = train_loader\n","        self.test_loader = test_loader\n","        self.node_id = node_id\n","        self.global_parameters = []\n","        self.accuracy = None\n","        self.model = SimpleNN(num_classes=8)\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=0.0001)\n","        self.accuracy_scores = []\n","        self.current_accuracy = 0\n","        self.accuracy_scores = []\n","        self.f1_scores = []\n","        self.precision_scores = []\n","        self.recall_scores = []\n","        self.weighting = weighting\n","        self.aggregation_methodology = aggregation_methodology\n","        self.balance_score = self.get_balance_score()\n","\n","    def get_model(self):\n","      return self.model\n","\n","    def get_balance_score(self):\n","        class_counts = np.zeros(10, dtype=int)  # MNIST has 10 classes (0-9)\n","        for _, label in self.__train_loader:\n","            class_counts[label] += 1\n","        total_samples = sum(class_counts)\n","        if total_samples == 0:\n","            return 0\n","        class_proportions = np.array(class_counts) / total_samples\n","        score = 1 - np.std(class_proportions)\n","        return score\n","\n","    def get_final_scores(self):\n","\n","      \"\"\"\n","      Convert performance metrics lists into a pandas DataFrame.\n","\n","      Parameters:\n","      accuracy_scores (list): List of accuracy scores.\n","      precision_scores (list): List of precision scores.\n","      recall_scores (list): List of recall scores.\n","      f1_scores (list): List of F1 scores.\n","\n","      Returns:\n","      pd.DataFrame: DataFrame containing the metrics.\n","      \"\"\"\n","      # Create a dictionary from the lists\n","      metrics_dict = {\n","          'Accuracy': self.accuracy_scores,\n","          'Precision': self.precision_scores,\n","          'Recall': self.recall_scores,\n","          'F1 Score': self.f1_scores\n","      }\n","\n","      # Convert the dictionary into a DataFrame\n","      df = pd.DataFrame(metrics_dict)\n","\n","      return df\n","\n","    def get_accuracy_score(self):\n","      return self.current_accuracy\n","\n","    def set_accuracy_score(self, accuracy):\n","      self.current_accuracy = accuracy\n","\n","    def get_node_id(self):\n","      return self.node_id\n","\n","    def get_test_loader(self) -> DataLoader:\n","        \"\"\"\n","        Return the testing DataLoader.\n","\n","        Returns:\n","        DataLoader: The testing DataLoader.\n","        \"\"\"\n","        return self.test_loader\n","\n","    def broadcast_parameters(self):\n","\n","        \"\"\"\n","        Return the model parameters.\n","\n","        Returns:\n","        dict: Dictionary of model parameters.\n","        \"\"\"\n","        return_list = []\n","        for param in self.model.parameters():\n","          return_list.append(param.clone())\n","\n","        return_list.insert(0, self.current_accuracy)\n","        return_list.insert(0, self.weighting)\n","        return_list.insert(0, self.balance_score)\n","\n","        return return_list\n","\n","\n","    def gather_parameters(self, params):\n","        print(\"Gathered Parameters for Node \" + str(self.node_id))\n","        self.global_parameters.append(params)\n","        print(\"Length of Gathered Parameters for Node \" + str(self.node_id) + \" : \" + str(len(self.global_parameters)))\n","\n","    def average_parameters(self):\n","      # Initialize a list to store the summed parameters\n","      averaged_params = []\n","\n","      params = self.global_parameters\n","      for inner_list in params:\n","        inner_list.pop(0)\n","        inner_list.pop(0)\n","        inner_list.pop(0)\n","      # Iterate over the parameters of the first model to initialize the structure of the average\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","      # Sum the parameters from each model\n","      for model_params in params:\n","          for i, param in enumerate(model_params):\n","              averaged_params[i] += param\n","\n","      # Divide by the number of models to get the average\n","      num_models = len(params)\n","      for i in range(len(averaged_params)):\n","          averaged_params[i] /= num_models\n","\n","      return averaged_params\n","\n","\n","    def size_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      weightings = []\n","\n","      for param in params:\n","        param.pop(0) ##Remove balance Score\n","        weighting = param.pop(0) ##Get weighting\n","        param.pop(0) ## Remove accuracy score\n","        weightings.append(weighting)\n","\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","          # Sum the parameters with their corresponding weights\n","      total_weight = 0\n","      for model_params, weight in zip(params, weightings):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * weight\n","          total_weight += weight\n","\n","      # Normalize by the total weight\n","      if total_weight > 0:\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_weight\n","\n","      return averaged_params\n","\n","\n","\n","    def accuracy_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      accuracies = []\n","\n","      for param in params:\n","        param.pop(0) ##Get rid of balance score\n","        param.pop(0) ##Get rid of Weighting\n","        accuracy = param.pop(0)\n","        print(\"Accuracy: \" + str(accuracy))\n","        accuracies.append(accuracy)\n","\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","          # Sum the parameters with their corresponding weights\n","      total_accuracies = 0\n","      for model_params, accuracy in zip(params, accuracies):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * accuracy\n","          total_accuracies += accuracy\n","\n","      # Normalize by the total weight\n","      if total_accuracies > 0:\n","          print(\"Total Accuracy: \" + str(total_accuracies))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_accuracies\n","\n","      return averaged_params\n","\n","    def selective_accuracy_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      accuracies = []\n","\n","      for param in params:\n","        param.pop(0) ##Get rid of balance score\n","        param.pop(0) ##Get rid of Weighting\n","        accuracy = param.pop(0)\n","        print(\"Accuracy: \" + str(accuracy))\n","        accuracies.append(accuracy)\n","\n","      # Identify the index of the node with the lowest accuracy\n","      min_accuracy_index = accuracies.index(min(accuracies))\n","      # Exclude the parameters of the node with the lowest accuracy\n","      filtered_params = [p for i, p in enumerate(params) if i != min_accuracy_index]\n","      filtered_accuracies = [a for i, a in enumerate(accuracies) if i != min_accuracy_index]\n","\n","      # Check if we have remaining nodes after exclusion\n","      if not filtered_params:\n","          raise ValueError(\"No parameters left to average after excluding the lowest accuracy node.\")\n","\n","      # Initialize averaged_params with zeros\n","      for param in filtered_params[0]:\n","          averaged_params.append(torch.zeros_like(param))\n","\n","      # Sum the parameters with their corresponding weights\n","      total_accuracies = 0\n","      for model_params, accuracy in zip(filtered_params, filtered_accuracies):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * accuracy\n","          total_accuracies += accuracy\n","\n","      # Normalize by the total weight\n","      if total_accuracies > 0:\n","          print(\"Total Accuracy: \" + str(total_accuracies))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_accuracies\n","\n","      return averaged_params\n","\n","\n","    def balance_average_parameters(self):\n","      averaged_params = []\n","      print(\"Size of global params: \" + str(len(self.global_parameters)))\n","      params = self.global_parameters\n","      balance_scores = []\n","\n","      for param in params:\n","        balance_score = param.pop(0) ##Store balance score\n","        param.pop(0) ##Get rid of Weighting\n","        param.pop(0) ##Get rid of Accuracy\n","        print(\"Balance Score: \" + str(balance_score))\n","        balance_scores.append(balance_score)\n","\n","      for param in params[0]:\n","          # Start with a tensor of zeros of the same shape as the parameter\n","          averaged_params.append(torch.zeros_like(param))\n","\n","      # Sum the parameters with their corresponding weights\n","      total_balance_scores = 0\n","      for model_params, balance_score in zip(params, balance_scores):\n","          if len(model_params) != len(averaged_params):\n","              raise ValueError(\"Mismatch in the number of parameters between models.\")\n","          for i, (param, avg_param) in enumerate(zip(model_params, averaged_params)):\n","              if param.shape != avg_param.shape:\n","                  raise RuntimeError(f\"Shape mismatch: {param.shape} != {avg_param.shape}\")\n","              averaged_params[i] += param * balance_score\n","          total_balance_scores += balance_score\n","\n","      # Normalize by the total weight\n","      if total_balance_scores > 0:\n","          print(\"Total Balance Scores: \" + str(total_balance_scores))\n","          for i in range(len(averaged_params)):\n","              averaged_params[i] /= total_balance_scores\n","\n","      return averaged_params\n","\n","\n","\n","\n","    def aggregate_parameters(self):\n","      if self.aggregation_methodology == \"average\":\n","        averaged_params = self.average_parameters()\n","      elif self.aggregation_methodology == \"size_average\":\n","        averaged_params = self.size_average_parameters()\n","      elif self.aggregation_methodology == \"accuracy_average\":\n","        averaged_params = self.accuracy_average_parameters()\n","      elif self.aggregation_methodology == \"balance_average\":\n","        averaged_params = self.balance_average_parameters()\n","      elif self.aggregation_methodology == \"selective_accuracy_average\":\n","        averaged_params = self.selective_accuracy_average_parameters()\n","      else:\n","        raise ValueError(\"Invalid aggregation methodology. Use 'average' or 'size_average' or 'accuracy_average'.\")\n","      print(\"Length of Averaged Params for node \" + str(self.node_id) + \" : \" + str(len(averaged_params)))\n","      self.set_parameters(averaged_params)\n","\n","      self.global_parameters = []\n","\n","\n","    def set_parameters(self, parameters):\n","\n","        \"\"\"\n","        Set the model parameters.\n","\n","        Parameters:\n","        parameters (dict): Dictionary of model parameters.\n","        \"\"\"\n","        # Convert the list of averaged parameters back into the correct format for the model\n","        print(\"Setting Parameters for node: \" + str(self.node_id))\n","        new_state_dict = dict(zip(self.model.state_dict().keys(), parameters))\n","        self.model.load_state_dict(new_state_dict)\n","        print(\"Set Parameters for node \" + str(self.node_id) + \" : \" + str(model_parameters_to_string(self.model)))\n","\n","\n","\n","    def train(self):\n","\n","      # Move model to the specified device\n","      self.model.to(device)\n","\n","      for epoch in range(NUM_LOCAL_EPOCHS):\n","\n","        self.model.train()\n","        running_loss = 0.0\n","\n","        for images, labels in self.__train_loader:\n","            # Move images and labels to the specified device\n","            images, labels = images.to(device), labels.to(device)\n","\n","            # Flatten the labels tensor to be 1D\n","            if len(labels.shape) == 2:\n","                labels = labels.squeeze(1)  # Remove the extra dimension\n","\n","            # Check for label values out of bounds\n","            if labels.max() >= 8:\n","                raise ValueError(f\"Label value {labels.max()} is out of bounds for the number of classes {8}.\")\n","\n","            # Ensure labels are 1D\n","            if len(labels.shape) != 1:\n","                raise ValueError(\"Labels tensor is not 1D. It should be of shape [batch_size].\")\n","\n","            self.optimizer.zero_grad()\n","            outputs = self.model(images)\n","\n","            # Ensure labels are of type long\n","            labels = labels.long()\n","\n","            loss = self.criterion(outputs, labels)\n","            loss.backward()\n","            self.optimizer.step()\n","\n","            running_loss += loss.item()\n","      # Print the average loss for this epoch\n","        print(f\"Epoch [{epoch+1}/{NUM_LOCAL_EPOCHS}], Training Loss: {running_loss / len(train_loader)}\")\n","\n","\n","    def evaluate(self):\n","        self.model.eval()  # Set the model to evaluation mode\n","\n","        all_labels = []\n","        all_predictions = []\n","\n","        with torch.no_grad():  # No need to calculate gradients during evaluation\n","            for images, labels in self.test_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = self.model(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                all_labels.extend(labels.cpu().numpy())\n","                all_predictions.extend(predicted.cpu().numpy())\n","\n","        # Convert lists to numpy arrays for sklearn metrics\n","        all_labels = np.array(all_labels).flatten()\n","        all_predictions = np.array(all_predictions)\n","\n","        # Calculate metrics\n","        accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","        precision = precision_score(all_labels, all_predictions, average='weighted')\n","        recall = recall_score(all_labels, all_predictions, average='weighted')\n","        f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","        self.accuracy_scores.append(accuracy)\n","        self.precision_scores.append(precision)\n","        self.recall_scores.append(recall)\n","        self.f1_scores.append(f1)\n","        self.set_accuracy_score(accuracy)\n","        return accuracy, precision, recall, f1\n","\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"qK8K79a2NKnM","executionInfo":{"status":"ok","timestamp":1729468504400,"user_tz":-660,"elapsed":8,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["def train_and_communicate(node, nodes):\n","    node.train()\n","    metrics = node.evaluate()\n","    print(\"Metrics for Node \" + str(node.get_node_id()) + \" : \" + str(metrics))\n","    # Send parameters to all other nodes\n","    for other_node in nodes:\n","      print(\"NODE \" + str(node.get_node_id()) + \"  HAS BROADCASTED \")\n","\n","      other_node.gather_parameters(node.broadcast_parameters())"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"TUE36X0v1pyp","executionInfo":{"status":"ok","timestamp":1729468504401,"user_tz":-660,"elapsed":9,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["def evaluate(model, test_loader):\n","  model.eval()  # Set the model to evaluation mode\n","\n","  all_labels = []\n","  all_predictions = []\n","\n","  with torch.no_grad():  # No need to calculate gradients during evaluation\n","      for images, labels in test_loader:\n","          images, labels = images.to(device), labels.to(device)\n","          outputs = model(images)\n","          _, predicted = torch.max(outputs.data, 1)\n","          all_labels.extend(labels.cpu().numpy())\n","          all_predictions.extend(predicted.cpu().numpy())\n","\n","  # Convert lists to numpy arrays for sklearn metrics\n","  all_labels = np.array(all_labels).flatten()\n","  all_predictions = np.array(all_predictions)\n","\n","    # Print the shapes of the arrays\n","  print(f\"Shape of all_labels: {all_labels.shape}\")\n","  print(f\"Shape of all_predictions: {all_predictions.shape}\")\n","\n","\n","  print(f\"Unique labels: {np.unique(all_labels)}\")\n","  print(f\"Unique predictions: {np.unique(all_predictions)}\")\n","\n","\n","  print(f\"Sample Labels: {all_labels[:10]}\")\n","  print(f\"Sample Predictions: {all_predictions[:10]}\")\n","\n","  print(\"Num Correct: \" + str(np.sum(all_predictions == all_labels)))\n","\n","  # Calculate metrics\n","  accuracy = np.sum(all_predictions == all_labels) / len(all_labels)\n","  precision = precision_score(all_labels, all_predictions, average='weighted')\n","  recall = recall_score(all_labels, all_predictions, average='weighted')\n","  f1 = f1_score(all_labels, all_predictions, average='weighted')\n","\n","  return accuracy, precision, recall, f1"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"YtHShANb18kl","executionInfo":{"status":"ok","timestamp":1729468504401,"user_tz":-660,"elapsed":9,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}}},"outputs":[],"source":["# Function to write the metrics to a CSV file\n","def write_metrics_to_csv(filename, metrics_list):\n","    file_exists = os.path.isfile(filename)\n","\n","    with open(filename, mode='a', newline='') as file:\n","        writer = csv.writer(file)\n","\n","        # Write the header only if the file is being created\n","        if not file_exists:\n","            writer.writerow(['Aggregation Method', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n","\n","        # Write the data\n","        writer.writerow(metrics_list)\n","\n","    print(f'Metrics written to {filename}')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"6HVY_x9mNP_r","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1729468519915,"user_tz":-660,"elapsed":9372,"user":{"displayName":"Mia Bodycomb","userId":"06843546590917137794"}},"outputId":"3c3830a2-2e19-4cc3-c194-728f8ddd7c7b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Aggregation Methodology: average\n","Downloading https://zenodo.org/records/10519652/files/bloodmnist.npz?download=1 to /root/.medmnist/bloodmnist.npz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 35461855/35461855 [00:01<00:00, 18171216.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Using downloaded and verified file: /root/.medmnist/bloodmnist.npz\n","Data has been loaded\n","Data has been split into 4 nodes\n","Size of subset 1: 125\n","Size of subset 2: 2345\n","Size of subset 3: 8506\n","Size of subset 4: 983\n","Data Loader Created\n","Round 0\n","Epoch [1/5], Training Loss: 5.730601668357849\n","Epoch [2/5], Training Loss: 6.883803129196167\n","Epoch [3/5], Training Loss: 2.1806061267852783\n","Epoch [4/5], Training Loss: 2.4689109325408936\n","Epoch [5/5], Training Loss: 2.179612874984741\n","Metrics for Node 0 : (0.32, 0.23276190476190475, 0.32, 0.2479365079365079)\n","NODE 0  HAS BROADCASTED \n","Gathered Parameters for Node 0\n","Length of Gathered Parameters for Node 0 : 1\n","Length of Averaged Params for node 0 : 4\n","Setting Parameters for node: 0\n","Set Parameters for node 0 : Model Parameters:\n","Name: fc1.weight, Shape: torch.Size([128, 196608])\n","tensor([[ 0.0002,  0.0020, -0.0017,  ..., -0.0008, -0.0002, -0.0008],\n","        [-0.0002, -0.0005, -0.0023,  ..., -0.0005,  0.0006, -0.0013],\n","        [ 0.0008,  0.0012, -0.0002,  ..., -0.0005, -0.0009,  0.0012],\n","        ...,\n","        [-0.0006,  0.0007,  0.0011,  ..., -0.0015, -0.0005, -0.0005],\n","        [-0.0024, -0.0009,  0.0003,  ..., -0.0021, -0.0012, -0.0012],\n","        [-0.0007,  0.0003,  0.0014,  ...,  0.0008, -0.0017,  0.0010]])\n","--------------------------------------------------\n","Name: fc1.bias, Shape: torch.Size([128])\n","tensor([ 7.6528e-04,  7.4866e-04, -1.6646e-03, -2.6805e-04,  8.2932e-04,\n","         4.2687e-04, -7.3511e-04, -1.7522e-03, -8.7485e-04,  4.8115e-04,\n","         1.7422e-03,  1.3379e-03,  1.2840e-03, -4.0191e-04, -1.1898e-03,\n","         1.9086e-03, -3.1283e-04, -9.5426e-04,  1.1239e-03,  1.5444e-03,\n","        -1.7818e-03, -2.5407e-03,  9.3843e-05, -6.2091e-04, -1.2216e-03,\n","        -7.6111e-04,  4.2296e-04, -2.0689e-03, -1.4306e-03,  1.8225e-03,\n","         2.2296e-03, -5.2858e-04, -3.4986e-04,  4.9810e-04,  1.3377e-03,\n","        -1.7450e-03, -4.5440e-04, -5.9750e-04,  1.6135e-04,  2.0868e-03,\n","        -1.8720e-03,  6.0704e-04,  2.0778e-03, -1.8718e-03,  1.4044e-03,\n","        -1.4671e-03, -1.9270e-03, -1.2042e-03,  1.7487e-05, -1.1965e-05,\n","        -2.2816e-03,  6.6966e-04,  1.1696e-03, -3.0746e-04,  1.2618e-03,\n","        -2.4279e-03, -1.8039e-03, -8.1290e-04,  1.9834e-03, -9.8311e-04,\n","        -1.3303e-03,  9.6166e-04, -1.2653e-03,  1.4082e-03, -2.5779e-03,\n","        -1.6706e-03, -1.0163e-03, -1.7615e-03,  1.5442e-03, -1.2550e-03,\n","        -1.2770e-03,  1.8499e-03, -2.0653e-03, -2.4100e-03,  1.8202e-03,\n","        -2.5954e-03, -5.9023e-04, -1.0674e-04,  1.9766e-03, -1.2568e-03,\n","        -1.8014e-03,  1.4893e-04,  1.1415e-03, -1.1631e-03, -3.5298e-04,\n","        -2.3815e-03, -1.4984e-03,  1.6347e-03, -1.2879e-03,  1.6026e-03,\n","        -1.4452e-03, -4.2752e-06,  1.6826e-03,  1.8638e-03, -1.1747e-03,\n","         1.1465e-03, -2.0425e-03,  1.7132e-03,  1.4195e-03,  3.7991e-04,\n","        -2.3116e-03, -2.3836e-04, -1.0442e-04, -8.7550e-04, -2.4112e-03,\n","         2.0015e-04, -7.5512e-04,  4.0353e-04, -1.3616e-03, -1.8918e-03,\n","         2.4550e-04, -1.9443e-03,  2.0142e-03,  1.7173e-03,  1.4898e-03,\n","         9.7173e-04,  1.5678e-03, -1.5163e-03,  1.3351e-03,  6.1463e-04,\n","        -2.2827e-03,  6.2898e-04, -9.6844e-04, -7.4126e-04,  1.6558e-03,\n","        -2.1953e-03,  1.5996e-03, -8.5998e-04])\n","--------------------------------------------------\n","Name: fc2.weight, Shape: torch.Size([8, 128])\n","tensor([[-0.0547,  0.0766,  0.0078,  ..., -0.0539,  0.0277, -0.0011],\n","        [ 0.0212, -0.0784, -0.0348,  ..., -0.0102, -0.0838,  0.0541],\n","        [-0.0251,  0.0216,  0.0011,  ..., -0.0681, -0.0187,  0.0566],\n","        ...,\n","        [-0.0359, -0.0096,  0.0367,  ..., -0.0021, -0.0668,  0.0640],\n","        [-0.0262, -0.0877, -0.0398,  ...,  0.0344, -0.0213, -0.0417],\n","        [ 0.0087,  0.0677,  0.0426,  ..., -0.0016, -0.0136, -0.0838]])\n","--------------------------------------------------\n","Name: fc2.bias, Shape: torch.Size([8])\n","tensor([-0.0290, -0.0611,  0.0063,  0.0631, -0.0787, -0.0278,  0.0156, -0.0352])\n","--------------------------------------------------\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Round 1\n","Epoch [1/5], Training Loss: 1.730550467967987\n","Epoch [2/5], Training Loss: 1.4315466284751892\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-c629184eff98>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_GLOBAL_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Number of training rounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Round \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_and_communicate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["aggregation_methodologies = ['average', 'size_average', 'accuracy_average', 'balance_average', 'selective_accuracy_average']\n","\n","for i in range(30):\n","  # for aggregation_methodology in aggregation_methodologies:\n","    aggregation_methodology = 'average'\n","    print(\"Aggregation Methodology: \" + aggregation_methodology)\n","    dataset, testing_set = load_data()\n","\n","    #split data into final testing and data for nodes\n","    subsets, dataset, weightings = split_data_nodes(dataset, 4)\n","\n","    #create the final test loader and set it\n","    final_test_loader = create_final_data_test_loader(testing_set)\n","\n","\n","    nodes = []\n","    for i in range(0,NUM_NODES):\n","      train_loader, val_loader =  create_data_loaders(subsets[i])\n","      node = Node(i, train_loader, val_loader, weightings[i], aggregation_methodology)\n","      nodes.append(node)\n","\n","\n","    # Training and aggregation process\n","    for _ in range(NUM_GLOBAL_EPOCHS):  # Number of training rounds\n","        print(\"Round \" + str(_))\n","        with concurrent.futures.ThreadPoolExecutor() as executor:\n","            executor.map(train_and_communicate, nodes, [nodes]*len(nodes))\n","\n","        # # Aggregation phase\n","        for node in nodes:\n","\n","          updated_params = node.aggregate_parameters()\n","\n","        time.sleep(1)  # Simulate time between rounds\n","\n","\n","    node = nodes[0]\n","\n","    accuracy, precision, recall, f1 = evaluate(node.get_model(), final_test_loader)\n","    filename = '/content/drive/My Drive/Swarm_Learning/bloodMNIST_reg.csv'\n","    metrics_list = [aggregation_methodology, accuracy, precision, recall, f1]\n","    write_metrics_to_csv(filename, metrics_list)\n","\n","\n","\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyPDtiL8EBiZfCiiDo6EIVs+"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}